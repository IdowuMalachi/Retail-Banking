# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18vUVb6sf8RzXJe6hiWm92Cr_vAqrhpPH
"""

# app.py  ‚Äî NovaPay Fraud Defense Platform (FAST + FIXED)
# ------------------------------------------------------
# Requires:
#   Models/rf_fraud_model.joblib
#   Models/rf_features.json     (list of training feature columns)
# Optional:
#   shap_values_rf.npy
#   X_test_for_shap.csv
#
# Run:
#   streamlit run app.py

import os
import json
from pathlib import Path

import numpy as np
import pandas as pd
import streamlit as st
import joblib

import matplotlib.pyplot as plt

# ----------------------------
# Paths
# ----------------------------
APP_DIR = Path(__file__).parent
DATA_DIR = APP_DIR / "Data"
MODELS_DIR = APP_DIR / "Models"

MODEL_PATH = MODELS_DIR / "rf_fraud_model.joblib"
FEATURES_PATH = MODELS_DIR / "rf_features.json"

SHAP_PATH = APP_DIR / "shap_values_rf.npy"
XTEST_PATH = APP_DIR / "X_test_for_shap.csv"


# ----------------------------
# Premium UI CSS
# ----------------------------
CUSTOM_CSS = """
<style>
.block-container { padding-top: 1.2rem; padding-bottom: 2rem; max-width: 1250px; }
div[data-testid="stSidebarContent"] { padding-top: 1rem; }

.hero {
  padding: 22px;
  border-radius: 18px;
  background: linear-gradient(135deg, rgba(79,70,229,0.25), rgba(16,185,129,0.12));
  border: 1px solid rgba(255,255,255,0.08);
}
.hero h1 { margin: 0.2rem 0 0.2rem 0; }

.badge {
  display: inline-block;
  padding: 6px 10px;
  border-radius: 999px;
  font-size: 12px;
  background: rgba(255,255,255,0.08);
  border: 1px solid rgba(255,255,255,0.10);
}

.card, .panel {
  border-radius: 16px;
  padding: 16px;
  background: rgba(255,255,255,0.04);
  border: 1px solid rgba(255,255,255,0.08);
}
.card h3, .panel h3 { margin-top: 0; }

.kpi-grid { display:flex; gap:12px; flex-wrap:wrap; margin-top:10px; }
.kpi-card{
  flex: 1 1 160px;
  padding:14px;
  border-radius:16px;
  background: rgba(255,255,255,0.04);
  border: 1px solid rgba(255,255,255,0.08);
}
.kpi-title{ font-size:12px; opacity:0.75; }
.kpi-value{ font-size:22px; font-weight:700; }
.kpi-sub{ font-size:12px; opacity:0.8; }

.smallmuted { opacity: 0.8; font-size: 13px; }
hr.soft { border:none; height:1px; background:rgba(255,255,255,0.08); margin:12px 0; }

.tag{
  display:inline-block;
  padding:6px 10px;
  border-radius:999px;
  font-size:12px;
  margin-right:6px;
  background:rgba(255,255,255,0.08);
  border:1px solid rgba(255,255,255,0.10);
}
</style>
"""


# ----------------------------
# Fast model + feature loading (cached)
# ----------------------------
@st.cache_resource
def load_model_and_features():
    if not MODEL_PATH.exists():
        return None, None, False, "Model file missing: Models/rf_fraud_model.joblib"

    model = joblib.load(MODEL_PATH)

    # Primary: your saved rf_features.json
    if FEATURES_PATH.exists():
        with open(FEATURES_PATH, "r") as f:
            features = json.load(f)
        if not isinstance(features, list) or len(features) == 0:
            return None, None, False, "Models/rf_features.json exists but is empty/invalid."
        return model, features, True, "Loaded model + rf_features.json"

    # Fallback: sklearn feature_names_in_
    if hasattr(model, "feature_names_in_"):
        features = list(model.feature_names_in_)
        return model, features, True, "Loaded model + feature_names_in_ from sklearn"

    return None, None, False, "No feature list found. Add Models/rf_features.json."


def safe_datetime_to_numeric(series: pd.Series) -> pd.Series:
    """
    Try parse datetime-like strings into UNIX seconds (float).
    If not datetime-like, return original series.
    """
    if series.dtype != "object":
        return series

    dt = pd.to_datetime(series, errors="coerce", utc=True)
    if dt.notna().sum() >= max(3, int(0.10 * len(series))):  # treat as datetime if enough parses
        return (dt.view("int64") / 1e9).astype("float64")  # seconds
    return series


def align_to_training_features(df: pd.DataFrame, features: list) -> pd.DataFrame:
    """
    CRITICAL FIX:
    Ensure scoring dataframe has EXACT same columns + order as training.
    Converts datetimes to numeric, fills missing cols, drops extras, forces numeric.
    """
    X = df.copy()

    # drop target if present
    X = X.drop(columns=["is_fraud"], errors="ignore")

    # try datetime conversion for object columns
    for c in X.columns:
        X[c] = safe_datetime_to_numeric(X[c])

    # add missing training features
    for col in features:
        if col not in X.columns:
            X[col] = 0

    # keep only training columns + correct order
    X = X[features]

    # numeric cleanup
    X = X.replace([np.inf, -np.inf], np.nan).fillna(0)
    X = X.apply(pd.to_numeric, errors="coerce").fillna(0)

    return X


def risk_tier(prob: float) -> str:
    if prob >= 0.80:
        return "Critical"
    if prob >= 0.60:
        return "High"
    if prob >= 0.35:
        return "Medium"
    return "Low"


def score_transactions(df: pd.DataFrame, model, features: list, threshold: float) -> pd.DataFrame:
    X = align_to_training_features(df, features)
    probs = model.predict_proba(X)[:, 1]

    out = df.copy()
    out["fraud_probability"] = probs
    out["fraud_flag"] = (probs >= threshold).astype(int)
    out["risk_tier"] = [risk_tier(p) for p in probs]
    return out


def metric_row(scored_df: pd.DataFrame):
    total = len(scored_df)
    flagged = int((scored_df["fraud_flag"] == 1).sum())
    crit = int((scored_df["risk_tier"] == "Critical").sum())
    high = int((scored_df["risk_tier"] == "High").sum())
    avg_prob = float(scored_df["fraud_probability"].mean()) if total else 0.0
    return total, flagged, crit, high, avg_prob


def generate_action_recommendation(row: pd.Series):
    """
    Simple analyst-style explanation rules (fast).
    Adjust freely.
    """
    reasons = []
    actions = []

    # Common feature names you might have (use whatever exists)
    def get_any(keys, default=None):
        for k in keys:
            if k in row.index:
                return row[k]
        return default

    amt = get_any(["amount_usd", "amount_src", "amount"], 0)
    ip = get_any(["ip_risk_score", "customer_avg_ip_risk"], 0)
    dev = get_any(["device_trust_score"], 1)
    v1 = get_any(["txn_velocity_1h"], 0)
    v24 = get_any(["txn_velocity_24h"], 0)

    if amt is not None and float(amt) > 1000:
        reasons.append("High transaction amount")
    if ip is not None and float(ip) > 0.6:
        reasons.append("Elevated IP risk")
    if dev is not None and float(dev) < 0.3:
        reasons.append("Low device trust score")
    if v1 is not None and float(v1) >= 5:
        reasons.append("High transaction velocity (1h)")
    if v24 is not None and float(v24) >= 12:
        reasons.append("High transaction velocity (24h)")

    if len(reasons) == 0:
        reasons.append("No strong red flags detected; risk likely driven by combined weak signals.")

    actions.extend([
        "Verify customer identity (KYC) if flagged",
        "Check device/IP fingerprint history",
        "Review recent transaction pattern for velocity spikes",
        "If confirmed fraud: block device + add to watchlist"
    ])

    return reasons, actions


def build_single_row(features, amount_usd, ip_risk, device_trust, v1, v24, age_days, corridor, loc_mismatch, new_device):
    """
    Build a single-row dataframe that matches training features.
    Strategy:
      - start with all zeros for training columns
      - populate common candidate names ONLY if they exist in training features
    """
    row = {c: 0 for c in features}

    candidates = {
        "amount_usd": amount_usd,
        "amount_src": amount_usd,
        "amount": amount_usd,

        "ip_risk_score": ip_risk,
        "customer_avg_ip_risk": ip_risk,

        "device_trust_score": device_trust,

        "txn_velocity_1h": int(v1),
        "txn_velocity_24h": int(v24),

        "account_age_days": int(age_days),

        "corridor_risk": corridor,

        "location_mismatch": int(loc_mismatch),
        "new_device": int(new_device),
    }

    for k, v in candidates.items():
        if k in row:
            row[k] = v

    return pd.DataFrame([row])


# ----------------------------
# Streamlit setup
# ----------------------------
st.set_page_config(page_title="NovaPay | AI Fraud Defense", page_icon="üõ°Ô∏è", layout="wide")
st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

model, features, LOADED, load_msg = load_model_and_features()

# Sidebar
st.sidebar.title("üß≠ NovaPay Console")

page = st.sidebar.radio(
    "Navigation",
    ["üè† Dashboard", "üß™ Batch Scoring", "üéØ Single Transaction", "üß† Explainability"],
    index=0
)

st.sidebar.markdown("---")
threshold = st.sidebar.slider("Fraud Threshold", 0.10, 0.99, 0.93, 0.01)
st.sidebar.caption("Raise threshold ‚Üí higher precision, lower recall. Lower threshold ‚Üí catch more fraud.")

st.sidebar.markdown("---")
st.sidebar.subheader("‚öôÔ∏è Model Status")
if LOADED:
    st.sidebar.success("Model loaded ‚úÖ")
    st.sidebar.caption(load_msg)
    st.sidebar.write(f"Training features: **{len(features):,}**")
else:
    st.sidebar.error("Model not ready ‚ùå")
    st.sidebar.caption(load_msg)
    st.stop()


# ----------------------------
# Dashboard
# ----------------------------
if page == "üè† Dashboard":
    st.markdown(
        """
        <div class="hero">
          <span class="badge">AI-Assisted Fraud Defense</span>
          <h1>üõ°Ô∏è NovaPay Fraud Defense Platform</h1>
          <div class="smallmuted">
            Upload transactions ‚Ä¢ Score fraud probability ‚Ä¢ Explain decisions ‚Ä¢ Monitor risk
          </div>
        </div>
        """,
        unsafe_allow_html=True
    )

    c1, c2, c3 = st.columns([1.2, 1, 1])

    with c1:
        st.markdown('<div class="card"><h3>What this app does</h3>', unsafe_allow_html=True)
        st.write(
            """
            - Scores transactions with a trained **Random Forest** fraud model
            - Produces **risk tiers** (Low ‚Üí Critical) and recommended actions
            - Supports analyst review & reporting (CSV export)
            """
        )
        st.markdown("</div>", unsafe_allow_html=True)

    with c2:
        st.markdown('<div class="card"><h3>Model</h3>', unsafe_allow_html=True)
        st.success("Ready ‚úÖ")
        st.write(f"Loaded feature columns: **{len(features)}**")
        st.write(f"Default threshold: **{threshold:.2f}**")
        st.markdown("</div>", unsafe_allow_html=True)

    with c3:
        st.markdown('<div class="card"><h3>Quick Start</h3>', unsafe_allow_html=True)
        st.write(
            """
            1) Go to **Batch Scoring**
            2) Upload your transactions CSV
            3) Review **High/Critical** risk
            4) Download scored output
            """
        )
        st.markdown("</div>", unsafe_allow_html=True)

    st.markdown("### üîé Demo (optional)")
    st.caption("If you put a sample CSV in the Data folder, it will show here.")

    demo_files = []
    if DATA_DIR.exists():
        demo_files = sorted([p for p in DATA_DIR.glob("*.csv")])

    if len(demo_files) == 0:
        st.info("No demo CSV found in `Data/`. Add one to preview scoring on the Dashboard.")
    else:
        demo_path = st.selectbox("Choose demo CSV", demo_files, format_func=lambda p: p.name)
        df_demo = pd.read_csv(demo_path)

        with st.spinner("Scoring demo‚Ä¶"):
            scored_demo = score_transactions(df_demo, model, features, threshold)

        total, flagged, crit, high, avg_prob = metric_row(scored_demo)

        m1, m2, m3, m4, m5 = st.columns(5)
        m1.metric("Transactions", f"{total:,}")
        m2.metric("Flagged", f"{flagged:,}")
        m3.metric("Critical", f"{crit:,}")
        m4.metric("High", f"{high:,}")
        m5.metric("Avg Risk", f"{avg_prob:.3f}")

        st.dataframe(scored_demo.head(25), use_container_width=True)


# ----------------------------
# Batch Scoring
# ----------------------------
elif page == "üß™ Batch Scoring":
    st.markdown("## üß™ Batch Scoring")
    st.caption("Upload a CSV ‚Üí score fraud probability ‚Üí review highest-risk cases ‚Üí download results.")

    st.markdown(
        """
        <div class="panel">
          <h3>üìÇ Upload Transactions</h3>
          <div class="smallmuted">You can upload a raw or engineered CSV. The app will auto-align to training features.</div>
        </div>
        """,
        unsafe_allow_html=True
    )

    uploaded = st.file_uploader("Upload CSV", type=["csv"], label_visibility="visible")
    if uploaded is None:
        st.info("Drop a CSV here or click **Browse files** to upload.")
        st.stop()

    df_in = pd.read_csv(uploaded)

    left, right = st.columns([1.4, 1])

    with left:
        st.markdown("### üëÄ Preview")
        st.dataframe(df_in.head(25), use_container_width=True)

    with right:
        st.markdown("### ‚öôÔ∏è Options")
        top_n = st.slider("Show top risky rows", 10, 200, 50, 10)
        show_only_flagged = st.checkbox("Show only flagged", value=False)

        st.markdown("<hr class='soft'/>", unsafe_allow_html=True)
        note = st.text_area(
            "Analyst note (optional)",
            height=90,
            placeholder="Example: Batch uploaded from settlement pipeline‚Ä¶"
        )

    with st.spinner("Scoring transactions‚Ä¶"):
        scored = score_transactions(df_in, model, features, threshold)

    if note.strip():
        scored["batch_note"] = note.strip()

    view_df = scored
    if show_only_flagged:
        view_df = scored[scored["fraud_flag"] == 1]

    total, flagged, crit, high, avg_prob = metric_row(scored)

    st.markdown(
        f"""
        <div class="kpi-grid">
          <div class="kpi-card"><div class="kpi-title">Transactions</div><div class="kpi-value">{total:,}</div><div class="kpi-sub">Rows scored</div></div>
          <div class="kpi-card"><div class="kpi-title">Flagged</div><div class="kpi-value">{flagged:,}</div><div class="kpi-sub">threshold {threshold:.2f}</div></div>
          <div class="kpi-card"><div class="kpi-title">Critical</div><div class="kpi-value">{crit:,}</div><div class="kpi-sub">risk tier</div></div>
          <div class="kpi-card"><div class="kpi-title">High</div><div class="kpi-value">{high:,}</div><div class="kpi-sub">risk tier</div></div>
          <div class="kpi-card"><div class="kpi-title">Average Risk</div><div class="kpi-value">{avg_prob:.3f}</div><div class="kpi-sub">mean probability</div></div>
        </div>
        """,
        unsafe_allow_html=True
    )

    st.markdown("### üìä Risk Breakdown")
    tier_counts = scored["risk_tier"].value_counts().reindex(["Low", "Medium", "High", "Critical"]).fillna(0)

    c1, c2 = st.columns([1, 1.2])

    with c1:
        st.markdown(
            "<span class='tag'>Low</span><span class='tag'>Medium</span><span class='tag'>High</span><span class='tag'>Critical</span>",
            unsafe_allow_html=True
        )
        fig = plt.figure(figsize=(6, 4))
        plt.bar(tier_counts.index.astype(str), tier_counts.values)
        plt.title("Risk Tier Distribution")
        plt.xlabel("Tier")
        plt.ylabel("Count")
        st.pyplot(fig)

    with c2:
        st.markdown("#### üî• Top Risk Cases")
        top_risky = scored.sort_values("fraud_probability", ascending=False).head(top_n)
        st.dataframe(top_risky, use_container_width=True)

    st.markdown("### ‚úÖ Scored Output")
    st.dataframe(view_df.head(200), use_container_width=True)

    st.markdown("### ‚¨áÔ∏è Export Results")
    colA, colB = st.columns(2)

    with colA:
        st.download_button(
            "Download FULL scored CSV",
            data=scored.to_csv(index=False).encode("utf-8"),
            file_name="novapay_scored_full.csv",
            mime="text/csv"
        )

    with colB:
        flagged_df = scored[scored["fraud_flag"] == 1]
        st.download_button(
            "Download ONLY flagged",
            data=flagged_df.to_csv(index=False).encode("utf-8"),
            file_name="novapay_scored_flagged_only.csv",
            mime="text/csv"
        )

    st.markdown("### üßæ Quick Summary (copy/paste)")
    st.code(
        f"""Batch Summary:
- Total transactions scored: {total:,}
- Flagged as fraud (threshold={threshold:.2f}): {flagged:,} ({(flagged/total*100 if total else 0):.2f}%)
- Critical risk: {crit:,}
- High risk: {high:,}
- Average fraud probability: {avg_prob:.3f}
""",
        language="text"
    )


# ----------------------------
# Single Transaction
# ----------------------------
elif page == "üéØ Single Transaction":
    st.markdown("## üéØ Single Transaction Scoring")
    st.caption("Enter key fields ‚Üí model scores fraud probability ‚Üí assistant suggests actions.")

    left, right = st.columns([1.1, 1])

    with left:
        st.markdown('<div class="card"><h3>Transaction Inputs</h3>', unsafe_allow_html=True)
        amount_usd = st.number_input("Amount (USD)", min_value=0.0, value=250.0, step=10.0)
        ip_risk_score = st.slider("IP risk score", 0.0, 1.0, 0.35, 0.01)

        # you said you can have negative device trust sometimes:
        # keep UI 0..1 but allow manual override if needed
        device_trust_score = st.slider("Device trust score", 0.0, 1.0, 0.70, 0.01)
        allow_negative = st.checkbox("My device_trust_score can be negative", value=False)
        if allow_negative:
            device_trust_score = st.number_input("Device trust score (manual)", value=float(device_trust_score), step=0.1)

        account_age_days = st.number_input("Account age (days)", min_value=0, value=120, step=1)
        txn_velocity_1h = st.number_input("Txn velocity (1h)", min_value=0, value=1, step=1)
        txn_velocity_24h = st.number_input("Txn velocity (24h)", min_value=0, value=3, step=1)
        corridor_risk = st.slider("Corridor risk", 0.0, 1.0, 0.25, 0.01)
        location_mismatch = st.checkbox("Location mismatch?", value=False)
        new_device = st.checkbox("New device?", value=False)
        run = st.button("üß† Score transaction")
        st.markdown("</div>", unsafe_allow_html=True)

    with right:
        st.markdown('<div class="card"><h3>AI Assistant</h3>', unsafe_allow_html=True)
        st.write("Explains the score in simple analyst language.")
        st.markdown("</div>", unsafe_allow_html=True)

        if run:
            row = build_single_row(
                features,
                amount_usd, ip_risk_score, device_trust_score,
                txn_velocity_1h, txn_velocity_24h,
                account_age_days, corridor_risk,
                location_mismatch, new_device
            )

            scored_one = score_transactions(row, model, features, threshold)
            prob = float(scored_one["fraud_probability"].iloc[0])
            flag = int(scored_one["fraud_flag"].iloc[0])
            tier = str(scored_one["risk_tier"].iloc[0])

            st.markdown("### Result")
            st.write(f"**Fraud probability:** `{prob:.4f}`")
            st.write(f"**Risk tier:** **{tier}**  |  **Threshold:** `{threshold:.2f}`")

            if flag == 1:
                st.error("‚ö†Ô∏è Decision: FLAG AS FRAUD (send to review)")
            else:
                st.success("‚úÖ Decision: ALLOW (monitor)")

            reasons, actions = generate_action_recommendation(scored_one.iloc[0])

            st.markdown("### Why this was flagged (signals)")
            for r in reasons:
                st.write(f"‚Ä¢ {r}")

            st.markdown("### Recommended actions")
            for a in actions:
                st.write(f"‚úÖ {a}")


# ----------------------------
# Explainability
# ----------------------------
elif page == "üß† Explainability":
    st.markdown("## üß† Explainability (SHAP)")
    st.caption("Loads saved SHAP artifacts from your notebook (no need for is_fraud column here).")

    if not (SHAP_PATH.exists() and XTEST_PATH.exists()):
        st.info(
            "SHAP artifacts not found in app root.\n\n"
            "Put these files beside app.py:\n"
            "- shap_values_rf.npy\n"
            "- X_test_for_shap.csv\n\n"
            "Then redeploy / rerun."
        )
        st.stop()

    shap_values = np.load(SHAP_PATH, allow_pickle=True)
    X_test = pd.read_csv(XTEST_PATH)

    if shap_values.ndim != 2:
        st.error(f"Unexpected SHAP array shape: {shap_values.shape}. Expected (n_samples, n_features).")
        st.stop()

    if X_test.shape[1] != shap_values.shape[1]:
        st.error(
            f"Mismatch: X_test has {X_test.shape[1]} columns but SHAP has {shap_values.shape[1]} features.\n"
            "Make sure X_test_for_shap.csv is the same one used to generate shap_values_rf.npy."
        )
        st.stop()

    st.markdown("### Global Feature Importance (Mean |SHAP|)")
    mean_abs = np.abs(shap_values).mean(axis=0)
    fi = pd.DataFrame({"feature": X_test.columns, "mean_abs_shap": mean_abs}).sort_values("mean_abs_shap", ascending=False)
    st.dataframe(fi.head(30), use_container_width=True)

    st.markdown("### Top 20 Features Plot")
    top20 = fi.head(20).iloc[::-1]  # reverse for barh
    fig = plt.figure(figsize=(8, 6))
    plt.barh(top20["feature"], top20["mean_abs_shap"])
    plt.title("Top 20 Features by Mean |SHAP| (Fraud class)")
    plt.xlabel("Mean |SHAP|")
    st.pyplot(fig)

    st.caption("For full beeswarm/force plots, keep them in your notebook (best for reports).")